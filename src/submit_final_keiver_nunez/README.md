
# üìå Submit final - Competencia Kaggle Gerencial

En esta carpeta encontrar√° la notebook de google colab que se emple√≥ para el submit final en kaggle. Adem√°s encontrar√° los archivos necesarios que debe cargar a la carpeta datasets de su google drive o jupyterlab antes de ejecutar la notebook de forma exitosa. 

Los archivos son: 

-gerencial_competencia_2025v_csv.xlsx.

-Indice-FACPCE.xlsx (contiene el coeficiente de ajuste a aplicar en la secci√≥n de Data Drifting de la notebook).

Si ejecuta la notebook desde Google Colab recuerde ejecutar la secci√≥n 1.1 del c√≥digo para montar Drive.
Si en cambio ejecuta la notebook desde JupyterLab puede omitir esta primera secci√≥n y avanzar a la secci√≥n 1.2.

Adicionalmente, se sum√≥ la secci√≥n 1.3.2 para ejecutar un sencillo EDA para explorar el dataset. El output de esta secci√≥n del c√≥digo es un archivo html que se guarda en la carpeta del experimento y se puede abrir con cualquier navegador web.


---

## üöÄ Caracter√≠sticas Principales
- ‚úî La notebook sube 11 submits a kaggle 
- ‚úî Escribe varios archivos en la carpeta del experimento: PARAM.yml, prediccion.txt, modelo.txt, impo.txt, BO_log.txt, modelo.model
- ‚úî Dentro del archivo BO_log.txt se encuentran los outputs de la optimizaci√≥n bayesiana realizada.
- ‚úî Los hiperpar√°metros fijos usados para entrenar el modelo fueron:
-     bjective= "binary",
      metric= "auc",
      first_metric_only= TRUE,
      boost_from_average= TRUE,
      feature_pre_filter= FALSE,
      verbosity= -100,
      force_row_wise= TRUE, 
      seed= PARAM$semilla_primigenia,
      max_bin= 31,
      learning_rate= 0.02
      num_iterations= 2048,  
      early_stopping_rounds= 300
  
- ‚úî Los mejores hiperpar√°metros encontrados por la BO con un total de 20 iteraciones fueron:
-     num_leaves = 
      min_data_in_leaf =
      feature_fraction = 

---

## üß† Tecnolog√≠as Usadas
- Python 3 / R
- LightGBM
- data.table
- mlrMBO
- DiceKriging
- JupyterLab
- Google Cloud

---

## üë§ Autor
**Keiver Nu√±ez**  
