{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keiverdatascience/labo2025v/blob/main/src/submit_final_keiver_nunez/submit_final_KeiverNunez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "859d38e7-11c0-48bc-978a-d0e907f19ed1",
      "metadata": {
        "id": "859d38e7-11c0-48bc-978a-d0e907f19ed1"
      },
      "source": [
        "# Competición Kaggle - Modalidad Gerencial\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29c586e3-ed7d-44b2-92a0-f19669f06940",
      "metadata": {
        "id": "29c586e3-ed7d-44b2-92a0-f19669f06940"
      },
      "source": [
        "A través del siguiente notebook para la modalidad gerencial, se propone un modelo que tiene como objetivo  predecir que clientes de Paquete Premium de la foto al 30-septiembre-2021 se darán de baja durante noviembre-2021, es decir predecir las BAJA+2 de la foto de 202109."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo de predicción - modalidad gerencial"
      ],
      "metadata": {
        "id": "sIqZe7PqlDYb"
      },
      "id": "sIqZe7PqlDYb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1  Seteo del ambiente en Google Colab"
      ],
      "metadata": {
        "id": "PX0qg_c0yqob"
      },
      "id": "PX0qg_c0yqob"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGY7H9xza7Zr"
      },
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
      ],
      "id": "NGY7H9xza7Zr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PupIBNba7Zr"
      },
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ],
      "id": "7PupIBNba7Zr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LpZCst5a7Zs"
      },
      "outputs": [],
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive', force_remount= True)"
      ],
      "id": "9LpZCst5a7Zs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYC_F-wla7Zs"
      },
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "*   Bajar el **dataset_historico** al Google Drive y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "*  Copiar en drive el archivo indice-FAPCE y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ],
      "id": "JYC_F-wla7Zs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWLelftXa7Zt"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/labo1\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/labo1\" /content/buckets/b1\n",
        "\n",
        "mkdir -p ~/.kaggle\n",
        "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "webfiles=\"https://storage.googleapis.com/open-courses/austral2025-af91/\"\n",
        "destino_local=\"/content/datasets\"\n",
        "destino_bucket=\"/content/buckets/b1/datasets\"\n",
        "\n",
        "\n",
        "archivo=\"dataset_pequeno.csv\"\n",
        "\n",
        "if ! test -f $destino_bucket/$archivo; then\n",
        "  wget  $webfiles/$archivo  -O $destino_bucket/$archivo\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $destino_local/$pequeno; then\n",
        "  cp  $destino_bucket/$archivo  $destino_local/$archivo\n",
        "fi\n",
        "\n",
        "#-------\n",
        "\n",
        "archivo=\"gerencial_competencia_2025.csv.gz\"\n",
        "\n",
        "if ! test -f $destino_bucket/$archivo; then\n",
        "  wget  $webfiles/$archivo  -O $destino_bucket/$archivo\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $destino_local/$pequeno; then\n",
        "  cp  $destino_bucket/$archivo  $destino_local/$archivo\n",
        "fi\n",
        "\n",
        "#-------\n",
        "\n",
        "archivo=\"Indice-FACPCE.xlsx\"\n",
        "\n",
        "if ! test -f $destino_bucket/$archivo; then\n",
        "  wget  $webfiles/$archivo  -O $destino_bucket/$archivo\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $destino_local/$pequeno; then\n",
        "  cp  $destino_bucket/$archivo  $destino_local/$archivo\n",
        "fi\n"
      ],
      "id": "XWLelftXa7Zt"
    },
    {
      "cell_type": "markdown",
      "id": "85171302-a2d6-48cb-b9b2-8d839a276859",
      "metadata": {
        "id": "85171302-a2d6-48cb-b9b2-8d839a276859"
      },
      "source": [
        "## 1.2 Inicializacion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSU5vi00CPRS"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje **R** Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
      ],
      "id": "eSU5vi00CPRS"
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "EL8wdHaUs59K"
      },
      "id": "EL8wdHaUs59K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iE0U4_WCPRT"
      },
      "outputs": [],
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ],
      "id": "1iE0U4_WCPRT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalo paquete R.utils"
      ],
      "metadata": {
        "id": "XeoUXjZvm_hq"
      },
      "id": "XeoUXjZvm_hq"
    },
    {
      "cell_type": "code",
      "source": [
        "require(\"data.table\")\n",
        "\n",
        "if( !require(\"R.utils\")) install.packages(\"R.utils\")\n",
        "require(\"R.utils\")"
      ],
      "metadata": {
        "id": "atmIUEUNUrK5",
        "collapsed": true
      },
      "id": "atmIUEUNUrK5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Semilla primigenia y N° experimento\n",
        "No olvide modificar su semilla primigenia y el nombre del experimento se quiere tener trazabilidad de los resultados"
      ],
      "metadata": {
        "id": "BsxZ_ONyj9L_"
      },
      "id": "BsxZ_ONyj9L_"
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM <- list()\n",
        "PARAM$semilla_primigenia <- 245681\n",
        "\n",
        "PARAM$experimento <- 1011\n",
        "PARAM$dataset <- \"gerencial_competencia_2025.csv.gz\""
      ],
      "metadata": {
        "id": "peRH7ySLCPRV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "peRH7ySLCPRV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Carpeta del Experimento"
      ],
      "metadata": {
        "id": "NoJbKo_4NG8A"
      },
      "id": "NoJbKo_4NG8A"
    },
    {
      "cell_type": "code",
      "source": [
        "# carpeta de trabajo\n",
        "\n",
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento_folder <- paste0(\"EF\", PARAM$experimento)\n",
        "dir.create(experimento_folder, showWarnings=FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
      ],
      "metadata": {
        "id": "1gZD6ZMvCPRV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "1gZD6ZMvCPRV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3   Preprocesamiento del dataset"
      ],
      "metadata": {
        "id": "YVKBfLtkR8SO"
      },
      "id": "YVKBfLtkR8SO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3.1 DT incorporar dataset"
      ],
      "metadata": {
        "id": "cr3K0RPVRjq6"
      },
      "id": "cr3K0RPVRjq6"
    },
    {
      "cell_type": "code",
      "source": [
        "# lectura del dataset\n",
        "dataset <- fread(paste0(\"/content/datasets/\", PARAM$dataset))"
      ],
      "metadata": {
        "id": "Xi0emX2ECPRV"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Xi0emX2ECPRV"
    },
    {
      "cell_type": "code",
      "source": [
        "colnames(dataset)"
      ],
      "metadata": {
        "id": "uB_b7vh7xNpf"
      },
      "id": "uB_b7vh7xNpf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3.2 Rápido y breve EDA para explorar los datos. Este paso lo puede omitir si es una persona ansiosa"
      ],
      "metadata": {
        "id": "LePAd7o5wmkv"
      },
      "id": "LePAd7o5wmkv"
    },
    {
      "cell_type": "code",
      "source": [
        "if( !require(\"DataExplorer\")) install.packages(\"DataExplorer\")\n",
        "require(\"DataExplorer\")\n",
        "\n",
        "create_report(dataset, output_file = \"EDA_automatico.html\")"
      ],
      "metadata": {
        "id": "bM0f6RYOsR9c"
      },
      "id": "bM0f6RYOsR9c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3.3  CA  Catastrophe Analysis - Reparar variables rotas\n",
        "Se intentan reparar las variables que para un mes están con todos los valores en cero."
      ],
      "metadata": {
        "id": "MWuPzK3nSLY3"
      },
      "id": "MWuPzK3nSLY3"
    },
    {
      "cell_type": "code",
      "source": [
        "head(dataset[foto_mes == 202006])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rzqpZmds0777"
      },
      "id": "rzqpZmds0777",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El método que se utiliza es **Machine Learning** se asigna NA also valores."
      ],
      "metadata": {
        "id": "UAI16-yCVcBS"
      },
      "id": "UAI16-yCVcBS"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[ foto_mes==202006, internet:=NA]\n",
        "dataset[ foto_mes==202006, mrentabilidad:=NA]\n",
        "dataset[ foto_mes==202006, mrentabilidad_annual:=NA]\n",
        "dataset[ foto_mes==202006, mcomisiones:=NA]\n",
        "dataset[ foto_mes==202006, mactivos_margen:=NA]\n",
        "dataset[ foto_mes==202006, mpasivos_margen:=NA]\n",
        "dataset[ foto_mes==202006, mcuentas_saldo:=NA]\n",
        "dataset[ foto_mes==202006, ctarjeta_visa_transacciones:=NA]\n",
        "dataset[ foto_mes==202006, mtarjeta_visa_consumo:=NA]\n",
        "dataset[ foto_mes==202006, mtarjeta_master_consumo:=NA]\n",
        "dataset[ foto_mes==202006, ccallcenter_transacciones:=NA]\n",
        "dataset[ foto_mes==202006, chomebanking_transacciones:=NA]\n",
        "dataset[ foto_mes==202006, chomebanking_transacciones:=NA]"
      ],
      "metadata": {
        "id": "sTmliO_FXv9E"
      },
      "id": "sTmliO_FXv9E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3.3  DR  Data Drifting\n",
        "Se intenta corregir el data drifting, ajustado por FACPCE"
      ],
      "metadata": {
        "id": "-4NiANYFSYHG"
      },
      "id": "-4NiANYFSYHG"
    },
    {
      "cell_type": "code",
      "source": [
        "if( !require(\"readxl\")) install.packages(\"readxl\")\n",
        "require(\"readxl\")\n",
        "if( !require(\"data.table\")) install.packages(\"data.table\")\n",
        "require(\"data.table\")\n",
        "if( !require(\"dplyr\")) install.packages(\"dplyr\")\n",
        "require(\"dplyr\")\n",
        "\n",
        "fapce <- read_excel(\"/content/datasets/Indice-FACPCE.xlsx\", col_types = c(\"text\", \"text\", \"text\")) %>%\n",
        "  mutate(\n",
        "    # ---- FOTO_MES CORREGIDO ----\n",
        "    # Eliminar el último caracter: \"2020050\" → \"202005\"\n",
        "    foto_mes = gsub(\"[^0-9]\", \"\", foto_mes),\n",
        "    foto_mes = substr(foto_mes, 1, 6),\n",
        "\n",
        "    # ---- IPC ----\n",
        "    #IPC = gsub(\"[^0-9]\", \"\", IPC),\n",
        "    IPC = as.numeric(IPC),\n",
        "\n",
        "    # ---- coeficiente ajustes ----\n",
        "    coeficiente_de_ajuste = gsub(\",\", \".\", coeficiente_de_ajuste),\n",
        "    coeficiente_de_ajuste = gsub(\"[^0-9.]\", \"\", coeficiente_de_ajuste),\n",
        "    coeficiente_de_ajuste = as.numeric(coeficiente_de_ajuste)\n",
        "  ) %>%\n",
        "  as.data.table()"
      ],
      "metadata": {
        "id": "L85A2lwKSe3k"
      },
      "id": "L85A2lwKSe3k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  head(fapce)"
      ],
      "metadata": {
        "id": "ZIVz9Sxs-QPp",
        "collapsed": true
      },
      "id": "ZIVz9Sxs-QPp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset <- as.data.table(dataset)\n",
        "\n",
        "# asegurar foto_mes como texto tipo \"202005\"\n",
        "dataset[, foto_mes := as.character(foto_mes)]\n",
        "dataset[, foto_mes := gsub(\"[^0-9]\", \"\", foto_mes)]\n",
        "dataset[, foto_mes := substr(foto_mes, 1, 6)]"
      ],
      "metadata": {
        "id": "NiWtzRNI5mL2"
      },
      "id": "NiWtzRNI5mL2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_borrar <- c(\"coeficiente_de_ajuste\", \"coeficiente_de_ajuste.x\", \"coeficiente_de_ajuste.y\")\n",
        "\n",
        "for (col in cols_borrar) {\n",
        "  if (col %in% names(dataset)) dataset[, (col) := NULL]\n",
        "}\n",
        "\n",
        "dataset <- merge(\n",
        "  dataset,\n",
        "  fapce[, .(foto_mes, coeficiente_de_ajuste)],\n",
        "  by = \"foto_mes\",\n",
        "  all.x = TRUE\n",
        ")"
      ],
      "metadata": {
        "id": "nNg0P452512m"
      },
      "id": "nNg0P452512m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MERGE POR FOTO_MES\n",
        "vars_ajustar <- c(\n",
        "  \"mrentabilidad\",\n",
        "  \"mrentabilidad_annual\",\n",
        "  \"mcomisiones\",\n",
        "  \"mactivos_margen\",\n",
        "  \"mpasivos_margen\",\n",
        "  \"mcuenta_corriente\",\n",
        "  \"mcaja_ahorro\",\n",
        "  \"mcuentas_saldo\",\n",
        "  \"mtarjeta_visa_consumo\",\n",
        "  \"mtarjeta_master_consumo\",\n",
        "  \"mprestamos_personales\",\n",
        "  \"mpayroll\",\n",
        "  \"Master_mpagominimo\",\n",
        "  \"Visa_mpagominimo\"\n",
        ")\n",
        "\n",
        "dataset[, (vars_ajustar) := lapply(.SD, as.numeric), .SDcols = vars_ajustar]"
      ],
      "metadata": {
        "id": "lHZdBkGe59Lt"
      },
      "id": "lHZdBkGe59Lt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\n",
        "  ,\n",
        "  (vars_ajustar) := lapply(.SD, function(x) x * coeficiente_de_ajuste),\n",
        "  .SDcols = vars_ajustar\n",
        "]"
      ],
      "metadata": {
        "id": "Idvn5se56BWW"
      },
      "id": "Idvn5se56BWW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head(dataset)"
      ],
      "metadata": {
        "id": "3VXk7JXc-C4p"
      },
      "id": "3VXk7JXc-C4p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3.4  FE_intra_manual Feature Engineering intra-mes\n",
        "\n",
        "Agrego campos nuevos dentro del mismo mes, SIN considerar la historia."
      ],
      "metadata": {
        "id": "7sppIDYeSn5X"
      },
      "id": "7sppIDYeSn5X"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[, foto_mes := as.numeric(foto_mes)]"
      ],
      "metadata": {
        "id": "C0jgwVgSDlF0"
      },
      "id": "C0jgwVgSDlF0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# esta funcion atributos presentes existe debido a que las modalidades poseen datasets con distinta cantidad de campos\n",
        "atributos_presentes <- function( patributos )\n",
        "{\n",
        "  atributos <- unique( patributos )\n",
        "  comun <- intersect( atributos, colnames(dataset) )\n",
        "\n",
        "  return(  length( atributos ) == length( comun ) )\n",
        "}\n",
        "\n",
        "# el mes 1,2, ..12\n",
        "if( atributos_presentes( c(\"foto_mes\") ))\n",
        "  dataset[, kmes := foto_mes %% 100]\n",
        "\n",
        "# variable extraida de una tesis de maestria de Irlanda\n",
        "if( atributos_presentes( c(\"mpayroll\", \"cliente_edad\") ))\n",
        "  dataset[, mpayroll_sobre_edad := mpayroll / cliente_edad]\n"
      ],
      "metadata": {
        "id": "qrqf3j3_St3p"
      },
      "id": "qrqf3j3_St3p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizo las columas del dataset a esta etapa\n",
        "colnames(dataset)"
      ],
      "metadata": {
        "id": "iC4viwOdY5Kp"
      },
      "id": "iC4viwOdY5Kp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación de Nuevas Variables\n",
        "\n",
        "rank_by_month <- function(x) {\n",
        "  x / (1 + abs(median(x, na.rm = TRUE)))\n",
        "}\n",
        "\n",
        "dataset[, disengagement_score :=\n",
        "          -rank_by_month(ctrx_quarter) +\n",
        "          -rank_by_month(mcuentas_saldo) +\n",
        "          -rank_by_month(Visa_mpagominimo) +\n",
        "          -rank_by_month(mpayroll_sobre_edad),\n",
        "        by = foto_mes]\n",
        "\n",
        "dataset[, revenue_stress :=\n",
        "          -mcuentas_saldo +\n",
        "          -Visa_mpagominimo]"
      ],
      "metadata": {
        "id": "jFXh2wUMy4Bt"
      },
      "id": "jFXh2wUMy4Bt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head(dataset)"
      ],
      "metadata": {
        "id": "Xny1mMUmCkh0"
      },
      "id": "Xny1mMUmCkh0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3.4 Feature engineering RF"
      ],
      "metadata": {
        "id": "FX_0iwrfrfKl"
      },
      "id": "FX_0iwrfrfKl"
    },
    {
      "cell_type": "code",
      "source": [
        "if( !require(\"lightgbm\")) install.packages(\"lightgbm\")\n",
        "require(\"lightgbm\")"
      ],
      "metadata": {
        "id": "E6K8fSjSrlgV"
      },
      "id": "E6K8fSjSrlgV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrsaXcQqcefM"
      },
      "outputs": [],
      "source": [
        "AgregaVarRandomForest <- function() {\n",
        "\n",
        "  cat( \"inicio AgregaVarRandomForest()\\n\")\n",
        "  gc(verbose= FALSE)\n",
        "  dataset[, clase01 := 0L ]\n",
        "  dataset[ clase_ternaria %in% PARAM$FE_rf$train$clase01_valor1,\n",
        "      clase01 := 1L ]\n",
        "\n",
        "  campos_buenos <- setdiff(\n",
        "    colnames(dataset),\n",
        "    c( \"clase_ternaria\", \"clase01\")\n",
        "  )\n",
        "\n",
        "  dataset[, entrenamiento :=\n",
        "    as.integer( foto_mes %in% PARAM$FE_rf$train$training )]\n",
        "\n",
        "  dtrain <- lgb.Dataset(\n",
        "    data = data.matrix(dataset[entrenamiento == TRUE, campos_buenos, with = FALSE]),\n",
        "    label = dataset[entrenamiento == TRUE, clase01],\n",
        "    free_raw_data = FALSE\n",
        "  )\n",
        "\n",
        "  modelo <- lgb.train(\n",
        "     data = dtrain,\n",
        "     param = PARAM$FE_rf$lgb_param,\n",
        "     verbose = -100\n",
        "  )\n",
        "\n",
        "  cat( \"Fin construccion RandomForest\\n\" )\n",
        "  # grabo el modelo, achivo .model\n",
        "  lgb.save(modelo, file=\"modelo.model\" )\n",
        "\n",
        "  qarbolitos <- copy(PARAM$FE_rf$lgb_param$num_iterations)\n",
        "\n",
        "  periodos <- dataset[ , unique( foto_mes ) ]\n",
        "\n",
        "  for( periodo in  periodos )\n",
        "  {\n",
        "    cat( \"periodo = \", periodo, \"\\n\" )\n",
        "    datamatrix <- data.matrix(dataset[ foto_mes== periodo, campos_buenos, with = FALSE])\n",
        "\n",
        "    cat( \"Inicio prediccion\\n\" )\n",
        "    prediccion <- predict(\n",
        "        modelo,\n",
        "        datamatrix,\n",
        "        type = \"leaf\"\n",
        "    )\n",
        "    cat( \"Fin prediccion\\n\" )\n",
        "\n",
        "    for( arbolito in 1:qarbolitos )\n",
        "    {\n",
        "       cat( arbolito, \" \" )\n",
        "       hojas_arbol <- unique(prediccion[ , arbolito])\n",
        "\n",
        "       for (pos in 1:length(hojas_arbol)) {\n",
        "         # el numero de nodo de la hoja, estan salteados\n",
        "         nodo_id <- hojas_arbol[pos]\n",
        "         dataset[ foto_mes== periodo, paste0(\n",
        "            \"rf_\", sprintf(\"%03d\", arbolito),\n",
        "             \"_\", sprintf(\"%03d\", nodo_id)\n",
        "          ) :=  as.integer( nodo_id == prediccion[ , arbolito]) ]\n",
        "\n",
        "       }\n",
        "\n",
        "       rm( hojas_arbol )\n",
        "    }\n",
        "    cat( \"\\n\" )\n",
        "\n",
        "    rm( prediccion )\n",
        "    rm( datamatrix )\n",
        "    gc(verbose= FALSE)\n",
        "  }\n",
        "\n",
        "  gc(verbose= FALSE)\n",
        "\n",
        "  # borro clase01 , no debe ensuciar el dataset\n",
        "  dataset[ , clase01 := NULL ]\n",
        "\n",
        "}\n"
      ],
      "id": "JrsaXcQqcefM"
    },
    {
      "cell_type": "code",
      "source": [
        "# Parametros de Feature Engineering  a partir de hojas de Random Forest\n",
        "\n",
        "# Estos CUATRO parametros son los que se deben modificar\n",
        "PARAM$FE_rf$arbolitos= 20\n",
        "PARAM$FE_rf$hojas_por_arbol= 16\n",
        "PARAM$FE_rf$datos_por_hoja= 150\n",
        "PARAM$FE_rf$mtry_ratio= 0.2\n",
        "\n",
        "# Estos son quasi fijos\n",
        "PARAM$FE_rf$train$clase01_valor1 <- c( \"BAJA+2\", \"BAJA+1\")\n",
        "PARAM$FE_rf$train$training <- c( 202101, 202102, 202103)\n",
        "\n",
        "# Estos TAMBIEN son quasi fijos\n",
        "PARAM$FE_rf$lgb_param <-list(\n",
        "    # parametros que se pueden cambiar\n",
        "    num_iterations = PARAM$FE_rf$arbolitos,\n",
        "    num_leaves  = PARAM$FE_rf$hojas_por_arbol,\n",
        "    min_data_in_leaf = PARAM$FE_rf$datos_por_hoja,\n",
        "    feature_fraction_bynode  = PARAM$FE_rf$mtry_ratio,\n",
        "\n",
        "    # para que LightGBM emule Random Forest\n",
        "    boosting = \"rf\",\n",
        "    bagging_fraction = ( 1.0 - 1.0/exp(1.0) ),\n",
        "    bagging_freq = 1.0,\n",
        "    feature_fraction = 1.0,\n",
        "\n",
        "    # genericos de LightGBM\n",
        "    max_bin = 31L,\n",
        "    objective = \"binary\",\n",
        "    first_metric_only = TRUE,\n",
        "    boost_from_average = TRUE,\n",
        "    feature_pre_filter = FALSE,\n",
        "    force_row_wise = TRUE,\n",
        "    verbosity = -100,\n",
        "    max_depth = -1L,\n",
        "    min_gain_to_split = 0.0,\n",
        "    min_sum_hessian_in_leaf = 0.001,\n",
        "    lambda_l1 = 0.0,\n",
        "    lambda_l2 = 0.0,\n",
        "\n",
        "    pos_bagging_fraction = 1.0,\n",
        "    neg_bagging_fraction = 1.0,\n",
        "    is_unbalance = FALSE,\n",
        "    scale_pos_weight = 1.0,\n",
        "\n",
        "    drop_rate = 0.1,\n",
        "    max_drop = 50,\n",
        "    skip_drop = 0.5,\n",
        "\n",
        "    extra_trees = FALSE\n",
        "  )"
      ],
      "metadata": {
        "id": "sl0wqkYJrrTd"
      },
      "id": "sl0wqkYJrrTd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering agregando variables de Random Forest\n",
        "AgregaVarRandomForest()"
      ],
      "metadata": {
        "id": "QKUFSNKqr9z0",
        "collapsed": true
      },
      "id": "QKUFSNKqr9z0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ncol(dataset)\n",
        "colnames(dataset)"
      ],
      "metadata": {
        "id": "DJZWya3dsFy9"
      },
      "id": "DJZWya3dsFy9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.3.5  FEhist Feature Engineering historico\n",
        "\n",
        "El Fature Engineering Histórico es la etapa que más aporta a la ganancia final, ya que enriquece cada registro del dataset con su historia."
      ],
      "metadata": {
        "id": "XaRBjQj8ZRUZ"
      },
      "id": "XaRBjQj8ZRUZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fe con deltas y  lags"
      ],
      "metadata": {
        "id": "EpIMGctjsPAk"
      },
      "id": "EpIMGctjsPAk"
    },
    {
      "cell_type": "markdown",
      "id": "cfe3b8cf-0707-4512-92e7-c1407bb3f73b",
      "metadata": {
        "id": "cfe3b8cf-0707-4512-92e7-c1407bb3f73b"
      },
      "source": [
        "Para cada campo del dataset original (*)\n",
        "se crean lo siguientes campos de a partir de la historia\n",
        "* lag1  lags de orden 1\n",
        "* delta1  =  valor actual - lag1\n",
        "* lag2  lags de orden 2\n",
        "* delta2  = valor actual - lag2\n",
        "* lag3 lags de orden 3\n",
        "* delta3 = valor actual - lag3\n",
        "\n",
        "\n",
        "(*) Excepto para los campos  <numero_de_cliente,  foto_mes,  clase_ternaria>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7850b948-827d-4a2a-b4d3-a5e459b47c11",
      "metadata": {
        "id": "7850b948-827d-4a2a-b4d3-a5e459b47c11"
      },
      "outputs": [],
      "source": [
        "# Feature Engineering Historico\n",
        "\n",
        "# todo es lagueable, menos la primary key y la clase\n",
        "cols_lagueables <- copy( setdiff(\n",
        "    colnames(dataset),\n",
        "    c(\"numero_de_cliente\", \"foto_mes\", \"clase_ternaria\")\n",
        ") )\n",
        "\n",
        "# https://rdrr.io/cran/data.table/man/shift.html\n",
        "\n",
        "# lags de orden 1\n",
        "dataset[,\n",
        "    paste0(cols_lagueables, \"_lag1\") := shift(.SD, 1, NA, \"lag\"),\n",
        "    by = numero_de_cliente,\n",
        "    .SDcols = cols_lagueables\n",
        "]\n",
        "\n",
        "# lags de orden 2\n",
        "dataset[,\n",
        "    paste0(cols_lagueables, \"_lag2\") := shift(.SD, 2, NA, \"lag\"),\n",
        "    by = numero_de_cliente,\n",
        "    .SDcols = cols_lagueables\n",
        "]\n",
        "\n",
        "# lags de orden 3\n",
        "dataset[,\n",
        "    paste0(cols_lagueables, \"_lag3\") := shift(.SD, 3, NA, \"lag\"),\n",
        "    by = numero_de_cliente,\n",
        "    .SDcols = cols_lagueables\n",
        "]\n",
        "\n",
        "# agrego los delta lags\n",
        "for (vcol in cols_lagueables)\n",
        "{\n",
        "    dataset[, paste0(vcol, \"_delta1\") := get(vcol) - get(paste0(vcol, \"_lag1\"))]\n",
        "    dataset[, paste0(vcol, \"_delta2\") := get(vcol) - get(paste0(vcol, \"_lag2\"))]\n",
        "    dataset[, paste0(vcol, \"_delta3\") := get(vcol) - get(paste0(vcol, \"_lag3\"))]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cea690d9-ece9-4852-a5e2-f337c31b6721",
      "metadata": {
        "id": "cea690d9-ece9-4852-a5e2-f337c31b6721"
      },
      "source": [
        "Verificacion de los campos recien creados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f772896b-595a-47d4-8905-c15304ac9452",
      "metadata": {
        "id": "f772896b-595a-47d4-8905-c15304ac9452",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "ncol(dataset)\n",
        "colnames(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf91ea5e-3341-4afb-8d05-cc4923d3d1e1",
      "metadata": {
        "id": "cf91ea5e-3341-4afb-8d05-cc4923d3d1e1"
      },
      "source": [
        "## 1.4 Modelado"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "526048e4-8cf2-4023-bd2d-a70e4e9ff157",
      "metadata": {
        "id": "526048e4-8cf2-4023-bd2d-a70e4e9ff157"
      },
      "source": [
        "### 1.4.1 Training Strategy\n",
        "\n",
        "Luego de revisados los resultados de los experimentos y dado que esta notebook se dirige a la modalidad gerencial, no se elimina el mes de la pandemia y además no se realiza ningún undersampling, y se entrena con todos los meses del dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f16bc1c1-b3ea-43ca-9d3c-53f8f9ab8ec1",
      "metadata": {
        "id": "f16bc1c1-b3ea-43ca-9d3c-53f8f9ab8ec1"
      },
      "source": [
        "Se hace una estrategia de entrenamiento muy sencilla, tomando todos los meses posibles, SIN eliminar nada x pandemia ni por ningun otro motivo\n",
        "\n",
        "* future = 202109  obviamente completo\n",
        "\n",
        "* final_train =  [ 202005, 202107 ]  SIN undersampling\n",
        "\n",
        "* training\n",
        "   * testing = NO HAY\n",
        "   * validation =  202107   completo, sin undersampling\n",
        "   * training = [ 202005, 202106 ]  donde se consideran el 100% de los CONTINUA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c9c0a42-ba58-4264-8566-091a6161716f",
      "metadata": {
        "id": "2c9c0a42-ba58-4264-8566-091a6161716f"
      },
      "outputs": [],
      "source": [
        "PARAM$trainingstrategy$validate <- c(202107)\n",
        "\n",
        "PARAM$trainingstrategy$training <- c(\n",
        "  202106, 202105, 202104, 202103, 202102, 202101,\n",
        "  202012, 202011, 202010, 202009, 202008, 202007,\n",
        "  202006, 202005\n",
        ")\n",
        "\n",
        "PARAM$trainingstrategy$training_pct <- 1.0\n",
        "\n",
        "\n",
        "PARAM$trainingstrategy$positivos <- c( \"BAJA+1\", \"BAJA+2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# seteo la clase01   1={BAJA+1, BAJA+2}   0={CONTINUA}\n",
        "dataset[, clase01 := ifelse( clase_ternaria %in% PARAM$trainingstrategy$positivos, 1, 0 )]"
      ],
      "metadata": {
        "id": "tv_trHWAj4a8"
      },
      "id": "tv_trHWAj4a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# los campos en los que se entrena\n",
        "campos_buenos <- copy( setdiff(\n",
        "    colnames(dataset), c(\"clase_ternaria\",\"clase01\",\"azar\"))\n",
        ")"
      ],
      "metadata": {
        "id": "Ud_XDKSIj8f_"
      },
      "id": "Ud_XDKSIj8f_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preparo para que se puede hacer undersampling de los CONTINUA\n",
        "#  solamente por un tema de VELOCIDAD\n",
        "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
        "dataset[, azar:=runif(nrow(dataset))]\n",
        "\n",
        "# undersampling de los CONTINUA\n",
        "dataset[, fold_train :=  foto_mes %in%  PARAM$trainingstrategy$training &\n",
        "    (clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\") |\n",
        "     azar < PARAM$trainingstrategy$training_pct ) ]\n",
        "\n",
        "\n",
        "if( !require(\"lightgbm\")) install.packages(\"lightgbm\")\n",
        "require(\"lightgbm\")\n",
        "\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset[fold_train == TRUE, campos_buenos, with = FALSE]),\n",
        "  label= dataset[fold_train == TRUE, clase01],\n",
        "  free_raw_data= TRUE\n",
        ")"
      ],
      "metadata": {
        "id": "rFKgZZPSj_Pa"
      },
      "id": "rFKgZZPSj_Pa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datos de validation\n",
        "dvalidate <- lgb.Dataset(\n",
        "  data= data.matrix(dataset[foto_mes %in% PARAM$trainingstrategy$validate, campos_buenos, with = FALSE]),\n",
        "  label= dataset[foto_mes %in% PARAM$trainingstrategy$validate, clase01],\n",
        "  free_raw_data= TRUE\n",
        ")\n",
        "\n",
        "nrow(dvalidate)"
      ],
      "metadata": {
        "id": "B3yo98kQkHcP"
      },
      "id": "B3yo98kQkHcP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "28e8f788-551c-4e50-9029-302ac0834287",
      "metadata": {
        "id": "28e8f788-551c-4e50-9029-302ac0834287"
      },
      "source": [
        "###  1.4.2 Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf5fc836-e222-4aeb-a6a8-157346895ef7",
      "metadata": {
        "id": "bf5fc836-e222-4aeb-a6a8-157346895ef7"
      },
      "source": [
        "* Clase binaria que se optimiza :  positivos = [ BAJA+1, BAJA+2 ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "885c03b5-77bc-4510-a930-0d1f14b52ffb",
      "metadata": {
        "id": "885c03b5-77bc-4510-a930-0d1f14b52ffb"
      },
      "source": [
        "* Metrica que se optimiza **AUC** Area Under Curve de la  ROC Curve. No se optimiza la función de ganancia tal como lo sugirió el profesor en el código original y como resultado de los experimentos hechos por la cohorte.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7e6f95c-66ef-4ab9-9ba3-fcc099816704",
      "metadata": {
        "id": "b7e6f95c-66ef-4ab9-9ba3-fcc099816704"
      },
      "source": [
        "* Cantidad de iteraciones inteligentes de la Optimizacion Bayesiana = **10**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe047a87-e2d0-4418-97dd-0a881e66d73a",
      "metadata": {
        "id": "fe047a87-e2d0-4418-97dd-0a881e66d73a"
      },
      "source": [
        "* Parametros no default, fijos de LightGBM que no se optimizan\n",
        "  * max_bin = 31  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e7da08e-fe57-4681-beff-11fe963116bd",
      "metadata": {
        "id": "1e7da08e-fe57-4681-beff-11fe963116bd"
      },
      "source": [
        "* Parametros que se optimizan en la Bayesian Optimization\n",
        "  * num_leaves  [8, 256]\n",
        "  * min_data_in_leaf  [8, 8192]\n",
        "  * feature_fraction [0.1, 0.9]\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# paquetes necesarios para la Bayesian Optimization\n",
        "if(!require(\"DiceKriging\")) install.packages(\"DiceKriging\")\n",
        "require(\"DiceKriging\")\n",
        "\n",
        "if(!require(\"mlrMBO\")) install.packages(\"mlrMBO\")\n",
        "require(\"mlrMBO\")"
      ],
      "metadata": {
        "id": "34V6y4GetKq_",
        "collapsed": true
      },
      "id": "34V6y4GetKq_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definición de la Bayesian Optimization\n",
        "<br> Si se desea optimizar un hiperparámetro que esta como fijo, debe QUITARSE de param_fijos y agregarse a PARAM$hipeparametertuning$hs"
      ],
      "metadata": {
        "id": "UFbDSYtH0TTT"
      },
      "id": "UFbDSYtH0TTT"
    },
    {
      "cell_type": "code",
      "source": [
        "# valor ridiculamente bajo para que corra rapido en el aula y no molestar a la *Modalidad Gerencial*\n",
        "PARAM$hipeparametertuning$num_interations <- 20\n",
        "\n",
        "# parametros fijos del LightGBM\n",
        "PARAM$lgbm$param_fijos <- list(\n",
        "  objective= \"binary\",\n",
        "  metric= \"auc\",\n",
        "  first_metric_only= TRUE,\n",
        "  boost_from_average= TRUE,\n",
        "  feature_pre_filter= FALSE,\n",
        "  verbosity= -100,\n",
        "  force_row_wise= TRUE, # para evitar warning\n",
        "  seed= PARAM$semilla_primigenia,\n",
        "  max_bin= 31,\n",
        "  learning_rate= 0.02,\n",
        " # feature_fraction= 0.5,\n",
        "  num_iterations= 2048,  # valor grande, lo limita early_stopping_rounds\n",
        "  early_stopping_rounds= 300\n",
        ")\n",
        "\n",
        "PARAM$hipeparametertuning$hs <- makeParamSet(\n",
        "  makeIntegerParam(\"num_leaves\", lower = 2L, upper = 256L),\n",
        "  makeIntegerParam(\"min_data_in_leaf\", lower = 2L, upper = 8192L),\n",
        "  makeNumericParam(\"feature_fraction\", lower= 0.1, upper= 0.9)\n",
        ")"
      ],
      "metadata": {
        "id": "5Uag3XGHqrfZ"
      },
      "id": "5Uag3XGHqrfZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Función \"señora caja negra\"  que es llamada para verificar la realidad por la Bayesian Optimization"
      ],
      "metadata": {
        "id": "FEa1UuuAz4yj"
      },
      "id": "FEa1UuuAz4yj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c10f535-8d90-47d1-ac3d-9b4c24ec21d2",
      "metadata": {
        "id": "2c10f535-8d90-47d1-ac3d-9b4c24ec21d2"
      },
      "outputs": [],
      "source": [
        "# En  x llegan los parmaetros de la bayesiana\n",
        "#  devuelve la AUC en validate del modelo entrenado\n",
        "#  en el parametro x llegan los hiperparámetros que se estan optimizando\n",
        "\n",
        "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
        "\n",
        "  # x pisa (o agrega) a param_fijos\n",
        "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
        "\n",
        "  # entreno LightGBM\n",
        "  modelo_train <- lgb.train(\n",
        "    data= dtrain,\n",
        "    valids= list(valid = dvalidate),\n",
        "    eval= \"auc\",\n",
        "    param= param_completo,\n",
        "    verbose= -100\n",
        "  )\n",
        "\n",
        "  # recupero la AUC en validation\n",
        "  AUC <- modelo_train$record_evals$valid$auc$eval[[modelo_train$best_iter]]\n",
        "\n",
        "  # esta es la forma de devolver un parametro extra\n",
        "  attr(AUC, \"extras\") <- list(\"num_iterations\"= modelo_train$best_iter)\n",
        "\n",
        "  # hago espacio en la memoria\n",
        "  rm(modelo_train)\n",
        "  gc(full= TRUE, verbose= FALSE)\n",
        "\n",
        "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
        "\n",
        "  return(AUC)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "267a35d4-adaf-4271-a875-3864111333b7",
      "metadata": {
        "id": "267a35d4-adaf-4271-a875-3864111333b7"
      },
      "source": [
        "Seteo de la Bayesian Optimization (complejo)\n",
        "<br> copiado y pegado de la documentación de la librería"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43c2a92d-1041-46b8-bff2-47297f209ed2",
      "metadata": {
        "id": "43c2a92d-1041-46b8-bff2-47297f209ed2"
      },
      "outputs": [],
      "source": [
        "configureMlr(show.learner.output = FALSE)\n",
        "\n",
        "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
        "# por favor, no desesperarse por lo complejo\n",
        "obj.fun <- makeSingleObjectiveFunction(\n",
        "    fn= EstimarGanancia_AUC_lightgbm, # la funcion que voy a maximizar\n",
        "    minimize= FALSE, # estoy Maximizando AUC\n",
        "    noisy= FALSE,\n",
        "    par.set= PARAM$hipeparametertuning$hs,\n",
        "    has.simple.signature= FALSE # paso los parametros en una lista\n",
        ")\n",
        "\n",
        "# cada 600 segundos guardo el resultado intermedio\n",
        "ctrl <- makeMBOControl(\n",
        "    save.on.disk.at.time= 600,\n",
        "    save.file.path= \"HT.RDATA\"\n",
        ")\n",
        "\n",
        "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
        "ctrl <- setMBOControlTermination(\n",
        "    ctrl,\n",
        "    iters= PARAM$hipeparametertuning$num_interations  # cantidad de iteraciones inteligentes\n",
        ")\n",
        "\n",
        "# defino el método estandar para la creacion de los puntos iniciales\n",
        "#   los \"No Inteligentes\"\n",
        "ctrl <- setMBOControlInfill(ctrl, crit = makeMBOInfillCritEI())\n",
        "\n",
        "# mas configuraciones\n",
        "surr.km <- makeLearner(\n",
        "    \"regr.km\",\n",
        "    predict.type= \"se\",\n",
        "    covtype= \"matern3_2\",\n",
        "    control= list(trace = TRUE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c1e5645-d26f-4923-a53f-f30471a4c4e8",
      "metadata": {
        "id": "6c1e5645-d26f-4923-a53f-f30471a4c4e8"
      },
      "source": [
        "Corrida de la Bayesian Optimization,  aqui se hace el trabajo pesado\n",
        "<br> por favor no se asuste con los warnings que pudieran aparecer\n",
        "\n",
        "Si corrío a medias y llegó a las iteraciones inteligentes, en el archivo binario HT.RDATA quedó lo ya procesado y es utilizado para retomar la corrida desde lo último que llegó a grabar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f8cab3f-c7e2-4802-bfd1-5ad509922a4e",
      "metadata": {
        "scrolled": true,
        "id": "1f8cab3f-c7e2-4802-bfd1-5ad509922a4e"
      },
      "outputs": [],
      "source": [
        "# inicio la optimizacion bayesiana\n",
        "\n",
        "cat(\"\\033[1;34m[INFO]\\033[0m Iniciando Optimización Bayesiana...\\n\")\n",
        "\n",
        "if (!file.exists(\"HT.RDATA\")) {\n",
        "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
        "} else {\n",
        "  cat(\"\\033[1;33m[RESUME]\\033[0m Archivo encontrado. Continuando...\\n\")\n",
        "  bayesiana_salida <- mboContinue(\"HT.RDATA\")\n",
        "}\n",
        "\n",
        "cat(\"\\n\\033[1;32m=============================================\\033[0m\\n\")\n",
        "cat(\"\\033[1;32mOPTIMIZACIÓN FINALIZADA\\033[0m\\n\")\n",
        "cat(\"Mejor resultado encontrado:\\n\")\n",
        "print(bayesiana_salida)\n",
        "cat(\"\\033[1;32m=============================================\\033[0m\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36307612-964f-4df3-907a-1bc3c095f178",
      "metadata": {
        "id": "36307612-964f-4df3-907a-1bc3c095f178"
      },
      "source": [
        "la bayesian optimization ha corrido, extraigo los mejores hiperparametros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c061a2a-3341-4006-a154-c95bb6cfd407",
      "metadata": {
        "id": "8c061a2a-3341-4006-a154-c95bb6cfd407"
      },
      "outputs": [],
      "source": [
        "# almaceno los resultados de la Bayesian Optimization\n",
        "# y capturo los mejores hiperparametros encontrados\n",
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "\n",
        "# ordeno en forma descendente por AUC = y\n",
        "setorder(tb_bayesiana, -y, -num_iterations)\n",
        "\n",
        "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
        "fwrite( tb_bayesiana,\n",
        "  file=\"BO_log.txt\",\n",
        "  sep=\"\\t\"\n",
        ")\n",
        "\n",
        "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
        "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
        "  1, # el primero es el de mejor AUC\n",
        "  setdiff(colnames(tb_bayesiana),\n",
        "    c(\"y\",\"dob\",\"eol\",\"error.message\",\"exec.time\",\"ei\",\"error.model\",\n",
        "      \"train.time\",\"prop.type\",\"propose.time\",\"se\",\"mean\",\"iter\")),\n",
        "  with= FALSE\n",
        "]\n",
        "\n",
        "print(PARAM$out$lgbm$mejores_hiperparametros)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddb554cb-1d96-4f6b-ae1c-c9a076f8dbdc",
      "metadata": {
        "id": "ddb554cb-1d96-4f6b-ae1c-c9a076f8dbdc"
      },
      "source": [
        "## 1.5 Produccion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c39492c3-756f-47a5-8747-93ade8275306",
      "metadata": {
        "id": "c39492c3-756f-47a5-8747-93ade8275306"
      },
      "source": [
        "Final Training\n",
        "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Final Training Dataset\n",
        "\n",
        "Aqui esta la gran decision de en qué meses hago el Final Training\n",
        "<br> debo utilizar los mejores hiperparámetros que encontré en la optimización bayesiana"
      ],
      "metadata": {
        "id": "xhKi_G_sYQqq"
      },
      "id": "xhKi_G_sYQqq"
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM$trainingstrategy$final_train <- c( 202107,\n",
        "  202106, 202105, 202104, 202103, 202102, 202101,\n",
        "  202012, 202011, 202010, 202009, 202008, 202007,\n",
        "  202006, 202005\n",
        ")\n",
        "\n",
        "dataset[, fold_final_train := foto_mes %in% PARAM$trainingstrategy$final_train ]\n",
        "\n",
        "# creo el dfinal_train en formato  LightGBM\n",
        "dfinal_train <- lgb.Dataset(\n",
        "  data= data.matrix(dataset[fold_final_train == TRUE, campos_buenos, with= FALSE]),\n",
        "  label= dataset[fold_final_train == TRUE, clase01],\n",
        "  free_raw_data= TRUE\n",
        ")\n",
        "\n",
        "nrow( dfinal_train) # verifico el tamaño"
      ],
      "metadata": {
        "id": "qyHfS_X0zd7o"
      },
      "id": "qyHfS_X0zd7o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Final Training Hyperparameters"
      ],
      "metadata": {
        "id": "HATRyklxYUpT"
      },
      "id": "HATRyklxYUpT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6b9f33c-e0a0-4ea6-8169-4a6180cc5d01",
      "metadata": {
        "id": "d6b9f33c-e0a0-4ea6-8169-4a6180cc5d01"
      },
      "outputs": [],
      "source": [
        "# uno los parametros fijos y los mejores encontrados de los variables\n",
        "fijos <- copy(PARAM$lgbm$param_fijos)\n",
        "\n",
        "# quito lo que optimice en la Bayesian Optimization\n",
        "fijos$num_iterations <- NULL\n",
        "fijos$early_stopping_rounds <- NULL\n",
        "\n",
        "# agrego a los hiperparametros fijos los que encontre con la Bayesian Optimization\n",
        "param_final <- c(fijos, PARAM$out$lgbm$mejores_hiperparametros)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05d3494f-0401-4f3e-9b69-f488a737879d",
      "metadata": {
        "id": "05d3494f-0401-4f3e-9b69-f488a737879d"
      },
      "source": [
        "##### Training\n",
        "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa239848-1c28-4ee5-984a-073903b4b279",
      "metadata": {
        "id": "fa239848-1c28-4ee5-984a-073903b4b279"
      },
      "outputs": [],
      "source": [
        "final_model <- lgb.train(\n",
        "  data= dfinal_train,\n",
        "  param= param_final,\n",
        "  verbose= -100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
        "\n",
        "lgb.save(final_model, \"modelo.txt\")"
      ],
      "metadata": {
        "id": "RC1ju-5MZN5s"
      },
      "id": "RC1ju-5MZN5s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ahora imprimo la importancia de variables\n",
        "\n",
        "tb_importancia <- as.data.table(lgb.importance(final_model))\n",
        "archivo_importancia <- \"impo.txt\"\n",
        "\n",
        "fwrite( tb_importancia,\n",
        "  file= archivo_importancia,\n",
        "  sep= \"\\t\"\n",
        ")"
      ],
      "metadata": {
        "id": "VEpv4RYOZHTU"
      },
      "id": "VEpv4RYOZHTU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7ea225b3-ce02-42e2-8330-b10ed250d172",
      "metadata": {
        "id": "7ea225b3-ce02-42e2-8330-b10ed250d172"
      },
      "source": [
        "#### Scoring"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "164981bb-f4c1-4228-8bc9-32e58a383c05",
      "metadata": {
        "id": "164981bb-f4c1-4228-8bc9-32e58a383c05"
      },
      "source": [
        "Aplico el modelo final a los datos del futuro"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM$trainingstrategy$future <- c(202109)\n",
        "\n",
        "dfuture <- dataset[ foto_mes %in% PARAM$trainingstrategy$future ]"
      ],
      "metadata": {
        "id": "eJ7RbT271v-R"
      },
      "id": "eJ7RbT271v-R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88ca61c8-fa24-4ce5-8be1-323aca018e8f",
      "metadata": {
        "id": "88ca61c8-fa24-4ce5-8be1-323aca018e8f"
      },
      "outputs": [],
      "source": [
        "# aplico final_model   a dfuture\n",
        "\n",
        "prediccion <- predict(\n",
        "  final_model,\n",
        "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Tabla Prediccion"
      ],
      "metadata": {
        "id": "79u0ZvjJZblE"
      },
      "id": "79u0ZvjJZblE"
    },
    {
      "cell_type": "code",
      "source": [
        "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
        "tb_prediccion[, prob := prediccion]\n",
        "\n",
        "# grabo las probabilidad del modelo\n",
        "#  me va a ser util para hacer Ensembles de modelos\n",
        "fwrite(tb_prediccion,\n",
        "  file= \"prediccion.txt\",\n",
        "  sep= \"\\t\"\n",
        ")"
      ],
      "metadata": {
        "id": "TB6aerGDZeTo"
      },
      "id": "TB6aerGDZeTo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8412d838-5bd5-454e-b3a9-5eaa18d80a50",
      "metadata": {
        "id": "8412d838-5bd5-454e-b3a9-5eaa18d80a50"
      },
      "source": [
        "## 1.6 Kaggle Competition Submit"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55970cb6-856a-46e3-a893-7f36b8352b8e",
      "metadata": {
        "id": "55970cb6-856a-46e3-a893-7f36b8352b8e"
      },
      "source": [
        "Genero las salidas y hago los submits a Kaggle\n",
        "<br>El notebook esta preparado para la Modalidad Gerencial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5fa2439-b0e9-49e0-a861-71d7315d6e1c",
      "metadata": {
        "id": "e5fa2439-b0e9-49e0-a861-71d7315d6e1c"
      },
      "outputs": [],
      "source": [
        "# genero archivos con los  \"envios\" mejores\n",
        "# suba TODOS los archivos a Kaggle\n",
        "\n",
        "PARAM$kaggle$competencia <- \"labo-i-2025-virtual-gerencial\"\n",
        "PARAM$kaggle$cortes <- seq(800, 1300, by = 50)\n",
        "\n",
        "# ordeno por probabilidad descendente\n",
        "setorder(tb_prediccion, -prob)\n",
        "\n",
        "dir.create(\"kaggle\")\n",
        "\n",
        "for (envios in PARAM$kaggle$cortes) {\n",
        "\n",
        "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
        "  tb_prediccion[1:envios, Predicted := 1L] # marco los primeros\n",
        "\n",
        "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
        "\n",
        "  # grabo el archivo\n",
        "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "    file= archivo_kaggle,\n",
        "    sep= \",\"\n",
        "  )\n",
        "\n",
        "  # subida a Kaggle, armo la linea de comando\n",
        "  comando <- \"kaggle competitions submit\"\n",
        "  competencia <- paste(\"-c\", PARAM$kaggle$competencia)\n",
        "  arch <- paste( \"-f\", archivo_kaggle)\n",
        "\n",
        "  mensaje <- paste0(\"-m 'envios=\", envios,\n",
        "  \"  semilla=\", PARAM$semilla_primigenia,\n",
        "    \"'\" )\n",
        "\n",
        "  linea <- paste( comando, competencia, arch, mensaje)\n",
        "\n",
        "  salida <- system(linea, intern=TRUE) # el submit a Kaggle\n",
        "  cat(salida, \"\\n\")\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grabo los parametros\n",
        "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
        "require(\"yaml\")\n",
        "\n",
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ],
      "metadata": {
        "id": "C94tK-xid6p2"
      },
      "id": "C94tK-xid6p2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b615a62-20cc-4e95-9af2-6b6db38d5efb",
      "metadata": {
        "id": "1b615a62-20cc-4e95-9af2-6b6db38d5efb"
      },
      "outputs": [],
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    },
    "language_info": {
      "name": "R"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}